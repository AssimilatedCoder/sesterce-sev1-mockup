# Sesterce GPU SuperCluster Calculator

A production-grade calculator for designing, costing, and monetizing large-scale GPU clusters (10,000â€“200,000 GPUs) based on NVIDIA GB200/GB300 NVL72 systems. Features sophisticated networking algorithms, dynamic service tier pricing, and comprehensive TCO analysis.

## ðŸ§® Complete Calculation Breakdown

### **CAPEX Categories**
```
Hardware CAPEX:
â”œâ”€â”€ GPU Systems
â”‚   â”œâ”€â”€ GB200 NVL72: $3,000,000 per rack (72 GPUs)
â”‚   â”œâ”€â”€ GB300 NVL72: $3,500,000 per rack (72 GPUs)
â”‚   â”œâ”€â”€ H100 SXM: $400,000 per system (8 GPUs)
â”‚   â””â”€â”€ H100 PCIe: $320,000 per system (8 GPUs)
â”‚
â”œâ”€â”€ Networking Equipment
â”‚   â”œâ”€â”€ Leaf Switches: $95,000-$180,000 each
â”‚   â”œâ”€â”€ Spine Switches: $120,000-$180,000 each
â”‚   â”œâ”€â”€ Core Switches: $180,000-$250,000 each
â”‚   â”œâ”€â”€ Cables & Transceivers: $400-$900 each
â”‚   â””â”€â”€ DPUs (BlueField-3): $2,500 each
â”‚
â”œâ”€â”€ Storage Infrastructure
â”‚   â”œâ”€â”€ VAST Universal: $8-12 per TB/month
â”‚   â”œâ”€â”€ WEKA Data Platform: $6-10 per TB/month
â”‚   â”œâ”€â”€ Pure FlashBlade: $4-8 per TB/month
â”‚   â””â”€â”€ Ceph (DIY): $2-4 per TB/month
â”‚
â”œâ”€â”€ Power & Cooling Infrastructure
â”‚   â”œâ”€â”€ UPS Systems: $150-200 per kW
â”‚   â”œâ”€â”€ PDUs: $50-100 per kW
â”‚   â”œâ”€â”€ Cooling (Liquid): $300-500 per kW
â”‚   â””â”€â”€ Facility Build-out: $1,000-2,000 per kW
â”‚
â””â”€â”€ Software Stack (Upfront)
    â”œâ”€â”€ Operating System: $0-5,000 per node
    â”œâ”€â”€ Container Platform: $0-15,000 per node
    â”œâ”€â”€ ML/AI Frameworks: $0-25,000 per node
    â””â”€â”€ Management Tools: $5,000-50,000 per node
```

### **OPEX Categories (Annual)**
```
Operational Expenses:
â”œâ”€â”€ Power & Energy
â”‚   â”œâ”€â”€ Electricity: $0.05-0.25 per kWh (region dependent)
â”‚   â”œâ”€â”€ PUE Multiplier: 1.05-1.50 (climate dependent)
â”‚   â””â”€â”€ Total Power Cost: MW Ã— 8760 hours Ã— rate Ã— PUE
â”‚
â”œâ”€â”€ Cooling & Facilities
â”‚   â”œâ”€â”€ Cooling OPEX: 15-25% of power cost
â”‚   â”œâ”€â”€ Facility Maintenance: 2-5% of facility CAPEX
â”‚   â””â”€â”€ Insurance: 0.5-1% of total CAPEX
â”‚
â”œâ”€â”€ Staffing Costs
â”‚   â”œâ”€â”€ Site Reliability Engineers: $150,000-250,000 each
â”‚   â”œâ”€â”€ Network Engineers: $120,000-200,000 each
â”‚   â”œâ”€â”€ Storage Engineers: $110,000-180,000 each
â”‚   â”œâ”€â”€ Security Engineers: $140,000-220,000 each
â”‚   â”œâ”€â”€ Data Center Technicians: $60,000-100,000 each
â”‚   â””â”€â”€ Management Overhead: 20-30% of staff costs
â”‚
â”œâ”€â”€ Software Licensing (Annual)
â”‚   â”œâ”€â”€ Operating System: $500-3,000 per node/year
â”‚   â”œâ”€â”€ Container Platform: $1,000-8,000 per node/year
â”‚   â”œâ”€â”€ Monitoring/Observability: $2,000-10,000 per node/year
â”‚   â”œâ”€â”€ Security Software: $1,500-5,000 per node/year
â”‚   â””â”€â”€ ML/AI Platform Licenses: $5,000-25,000 per node/year
â”‚
â”œâ”€â”€ Network & Connectivity
â”‚   â”œâ”€â”€ Internet Transit: $0.50-2.00 per Mbps/month
â”‚   â”œâ”€â”€ Private Peering: $500-2,000 per port/month
â”‚   â”œâ”€â”€ Cross-connects: $200-500 per connection/month
â”‚   â””â”€â”€ CDN Services: $0.02-0.10 per GB transferred
â”‚
â”œâ”€â”€ Storage OPEX
â”‚   â”œâ”€â”€ VAST/WEKA Support: 15-25% of license cost
â”‚   â”œâ”€â”€ Backup Services: $0.01-0.05 per GB/month
â”‚   â”œâ”€â”€ Archive Storage: $0.001-0.01 per GB/month
â”‚   â””â”€â”€ Data Transfer: $0.02-0.10 per GB
â”‚
â””â”€â”€ Maintenance & Support
    â”œâ”€â”€ Hardware Maintenance: 8-15% of hardware CAPEX
    â”œâ”€â”€ Software Support: 15-25% of software CAPEX
    â”œâ”€â”€ Vendor Support Contracts: $50,000-200,000/year
    â””â”€â”€ Spare Parts Inventory: 5-10% of hardware CAPEX
```

## ðŸŒ Networking Architecture Scaling

### **Architecture Selection Logic**
```
GPU Count â†’ Architecture Decision:

â‰¤ 2,000 GPUs: 2-Tier Leaf-Spine
â”œâ”€â”€ Leaf Switches: ceil(Racks/2) 
â”œâ”€â”€ Spine Switches: max(6, leafCount/4)
â””â”€â”€ Simple fabric, single failure domain

2,001-10,000 GPUs: 3-Tier with Pods  
â”œâ”€â”€ Pods: ceil(GPUs/1008)
â”œâ”€â”€ Leaf per Pod: ceil(1008/64) = 16
â”œâ”€â”€ Spine per Pod: max(6, 16Ã—9/128) = 6
â””â”€â”€ Pod isolation, manageable scale

> 10,000 GPUs: 3-Tier Multi-Pod with Core
â”œâ”€â”€ Core Groups: ceil(Pods/6) 
â”œâ”€â”€ Core Switches: GroupsÃ—12
â”œâ”€â”€ Pod Interconnect: Full mesh via core
â””â”€â”€ Massive scale, hierarchical design
```

### **Switch Count Calculations**
```
Per Pod (1,008 GPUs):
â”œâ”€â”€ Racks: 14 (72 GPUs each)
â”œâ”€â”€ Leaf Switches: 28 (2 per rack, dual-homed)
â”œâ”€â”€ Spine Switches: max(6, ceil(28 Ã— 9 rails / 128 ports)) = 16
â””â”€â”€ Redundancy: N+2 minimum for maintenance

Cable Requirements:
â”œâ”€â”€ Intra-Pod: 28 leafs Ã— 9 rails Ã— 16 GPUs/leaf = 4,032 cables
â”œâ”€â”€ Inter-Pod: 16 spines Ã— 64 ports Ã— 4 pods = 4,096 cables  
â””â”€â”€ Total: ~8,000+ cables per 4,000 GPU deployment

Switch Specifications:
â”œâ”€â”€ Spectrum-4 400G: 128 ports, $95,000
â”œâ”€â”€ Spectrum-4 800G: 64 ports, $120,000
â””â”€â”€ Quantum-3 800G: 144 ports, $180,000
```

## ðŸ’° Service Tier Pricing Model

### **Tier Structure & Multipliers**
```
Service Tiers (Default Distribution):

Tier 1: Bare Metal GPU Access (30%)
â”œâ”€â”€ Base Multiplier: 1.0Ã—
â”œâ”€â”€ Target: Advanced ML teams
â”œâ”€â”€ Features: Direct GPU access, SLURM/PBS
â””â”€â”€ SLA: 99.5%

Tier 2: Orchestrated Kubernetes (35%)  
â”œâ”€â”€ Base Multiplier: 1.45Ã—
â”œâ”€â”€ Target: Enterprise data science
â”œâ”€â”€ Features: Managed K8s, GPU operators
â””â”€â”€ SLA: 99.9%

Tier 3: Managed MLOps Platform (25%)
â”œâ”€â”€ Base Multiplier: 2.2Ã—
â”œâ”€â”€ Target: Turnkey AI/ML users
â”œâ”€â”€ Features: MLflow, AutoML, model registry
â””â”€â”€ SLA: 99.95%

Tier 4: Inference-as-a-Service (10%)
â”œâ”€â”€ Base Multiplier: 3.0Ã—
â”œâ”€â”€ Target: Production AI applications
â”œâ”€â”€ Features: Auto-scaling, <50ms latency
â””â”€â”€ SLA: 99.99%
```

### **Premium Service Modifiers**
```
Storage Performance:
â”œâ”€â”€ Extreme (All-NVMe): +0.25Ã— multiplier
â”œâ”€â”€ High Performance: +0.15Ã— multiplier  
â”œâ”€â”€ Balanced: +0.08Ã— multiplier
â””â”€â”€ Cost Optimized: +0.02Ã— multiplier

Compliance Certifications:
â”œâ”€â”€ HIPAA Healthcare: +0.15Ã— multiplier
â”œâ”€â”€ FedRAMP Authorized: +0.25Ã— multiplier
â”œâ”€â”€ SecNumCloud: +0.30Ã— multiplier
â””â”€â”€ Air-gapped: +0.50Ã— multiplier

Sustainability:
â”œâ”€â”€ 100% Renewable: +0.10Ã— multiplier
â”œâ”€â”€ Carbon Neutral: +0.15Ã— multiplier
â””â”€â”€ Net Zero: +0.20Ã— multiplier
```

### **Revenue Calculation Formula**
```
Base Cost Calculation:
â”œâ”€â”€ Annual Depreciation = Total CAPEX Ã· Depreciation Years
â”œâ”€â”€ Total Annual Cost = Annual Depreciation + Annual OPEX
â”œâ”€â”€ Effective GPU Hours = Actual GPUs Ã— 8760 Ã— Utilization%
â””â”€â”€ Base $/GPU-hour = Total Annual Cost Ã· Effective GPU Hours

Per-Tier Revenue:
â”œâ”€â”€ Effective Rate = Base Cost Ã— (Base Multiplier + Modifiers)
â”œâ”€â”€ Tier Revenue = Rate Ã— GPUs Ã— Tier% Ã— 8760 Ã— Utilization
â””â”€â”€ Total Revenue = Sum of all tier revenues

Blended Rate = Î£(Tier Rate Ã— Tier Percentage)
```

## ðŸ”§ Storage Network Sizing

### **Training Storage (VAST/WEKA)**
```
Bandwidth Calculation:
â”œâ”€â”€ Rule: 1.6 Tbps per 1,000 GPUs minimum
â”œâ”€â”€ 10,000 GPUs = 16 Tbps required
â”œâ”€â”€ 400G ports needed = ceil(16,000 Ã· 400) = 40 ports
â””â”€â”€ 64Ã—400G switches = ceil(16 Ã· 25.6) = 1 switch

Port Distribution:
â”œâ”€â”€ Frontend connections: 40 ports
â”œâ”€â”€ Backend storage: 20 ports  
â”œâ”€â”€ Redundancy: 2Ã— (80 total ports)
â””â”€â”€ Switch requirement: 2Ã— 64-port switches
```

### **Object Storage (Ceph)**
```
Bandwidth Calculation:
â”œâ”€â”€ Rule: 100G ports = GPUs Ã· 10
â”œâ”€â”€ 10,000 GPUs = 1,000 Ã— 100G ports
â”œâ”€â”€ 32Ã—100G switches = ceil(1,000 Ã· 32) = 32 switches
â””â”€â”€ Total fabric: 32 switches, 1,000 ports
```

## ðŸ“Š Key Formulas

### **System Sizing**
- `systems_needed = ceil(requested_gpus / gpus_per_system)`
- `actual_gpus = systems_needed Ã— gpus_per_system`
- `total_power_kw = systems_needed Ã— power_per_system`

### **Network Scaling**  
- `pods = ceil(actual_gpus / gpus_per_pod)`
- `leaf_switches = pods Ã— ceil(gpus_per_pod / gpus_per_leaf)`
- `spine_switches = max(6, ceil(leaf_switches Ã— rails_per_gpu / spine_ports))`

### **TCO Calculation**
- `annual_depreciation = total_capex / depreciation_years`
- `gpu_hour_cost = (annual_depreciation + annual_opex) / (gpus Ã— 8760 Ã— utilization)`
- `blended_rate = Î£(tier_rate Ã— tier_percentage)`

## ðŸš€ Deployment

### **Production (Nginx + Flask)**
```bash
./deploy-secure.sh              # Automated deployment
./start-nginx.sh                # Manual start
# Access: http://localhost:3025
```

### **Development**
```bash
cd sesterce-dashboard && npm start    # Frontend: port 3000
python calculator-api.py              # Backend: port 7779
```

## ðŸ”‘ Authentication
- Contact system administrator for login credentials
- JWT-based authentication with role-based access control

---

**Â© 2025 Sesterce Engineering. All rights reserved.**
